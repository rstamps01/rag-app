# File Path: /home/ubuntu/rag_app_v2/rag-app/backend/app/api/routes/documents.py

from fastapi import (
    APIRouter, 
    Depends, 
    HTTPException, 
    status, 
    UploadFile, 
    File, 
    BackgroundTasks,
    Query # Added for pagination
)
from typing import Any, List
import os
import uuid
import logging
import time
from sqlalchemy.orm import Session

# Import schemas, models, crud, deps, services
from ... import models, schemas, crud
from ...api import deps
from app.db import get_db   # from ...database import get_db
from ...services import document_processor # Import the new service
from ...core.config import settings # Import settings

# Setup logger
logger = logging.getLogger(__name__)

router = APIRouter()

# --- Configuration ---
# Use UPLOAD_DIR from settings if defined, otherwise use default
UPLOAD_DIR = getattr(settings, "UPLOAD_DIR", "/app/data/uploads") 
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ================================================
# Actual Document Processing Logic (using service)
# ================================================
async def process_document_pipeline(db: Session, doc_id: str, file_path: str, department: str):
    """
    Background task to process the uploaded document using the document_processor service.
    """
    logger.info(f"Starting processing pipeline for doc_id: {doc_id} in department: {department}")
    processing_start_time = time.time()
    success = False
    error_msg = None
    
    try:
        # 1. Update Status to Processing
        crud.crud_document.update_document_status(db, doc_id=doc_id, status="processing")
        logger.info(f"[{doc_id}] Status set to processing")

        # 2. Call the processing service
        success = await document_processor.process_and_store_document(
            doc_id=doc_id,
            file_path=file_path,
            department=department
        )

        # 3. Update Status based on service result
        if success:
            crud.crud_document.update_document_status(db, doc_id=doc_id, status="processed")
            processing_time = time.time() - processing_start_time
            logger.info(f"[{doc_id}] Processing completed successfully by service in {processing_time:.2f}s")
        else:
            # Error is logged within the service, just update status here
            error_msg = "Processing failed in document_processor service. Check logs for details."
            crud.crud_document.update_document_status(db, doc_id=doc_id, status="failed", error_message=error_msg)
            logger.error(f"[{doc_id}] Processing failed as reported by service.")

    except Exception as e:
        error_msg = f"Unhandled exception during processing pipeline for doc_id {doc_id}: {e}"
        logger.error(error_msg, exc_info=True)
        # Update Status to Failed with error message
        try:
            crud.crud_document.update_document_status(db, doc_id=doc_id, status="failed", error_message=str(e))
        except Exception as db_err:
            logger.error(f"[{doc_id}] Additionally failed to update status to failed in DB: {db_err}")
    finally:
        # Ensure the session is closed if opened within the task
        # This depends on how the DB session is passed or created
        pass 

# Wrapper to handle DB session within the background task
async def process_document_pipeline_wrapper(doc_id: str, file_path: str, department: str):
    db = next(get_db()) # Create a new session for this task
    try:
        await process_document_pipeline(db, doc_id, file_path, department)
    finally:
        db.close() # Ensure session is closed

# ================================================
# API Route Definitions with Authentication & DB
# ================================================

@router.post(
    "/", 
    response_model=schemas.Document, 
    status_code=status.HTTP_202_ACCEPTED
)
async def upload_document(
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: models.User = Depends(deps.get_current_user),
    file: UploadFile = File(...),
) -> Any:
    """
    Accepts a document upload, saves it, creates a DB record,
    and triggers background processing. Requires authentication.
    """
    # Generate unique ID and path
    doc_id = str(uuid.uuid4())
    safe_filename = f"{doc_id}_{os.path.basename(file.filename)}"
    file_location = os.path.join(UPLOAD_DIR, safe_filename)

    # Save the file
    try:
        file_content = await file.read()
        file_size = len(file_content)
        with open(file_location, "wb") as f:
            f.write(file_content)
        logger.info(f"File saved: {file_location}, size: {file_size}")
    except Exception as e:
        logger.error(f"Failed to save file {safe_filename}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to save uploaded file: {e}"
        )
    finally:
        await file.close()

    # Create initial document metadata object for DB
    doc_in = schemas.DocumentCreate(
        filename=file.filename, # Original filename
        content_type=file.content_type,
        size=file_size,
        status="pending"
    )

    # Save initial metadata to Database using CRUD
    try:
        db_doc = crud.crud_document.create_document(
            db=db, 
            doc_in=doc_in, 
            owner_id=current_user.id, 
            department=current_user.department, # Get department from logged-in user
            storage_path=file_location,
            doc_id=doc_id
        )
    except Exception as e:
        logger.error(f"Failed to save initial metadata for doc_id {doc_id}: {e}", exc_info=True)
        # Clean up saved file if DB entry fails
        if os.path.exists(file_location):
            try: os.remove(file_location) 
            except OSError: pass
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to create document record in database: {e}"
        )

    # Add the processing task to run in the background
    background_tasks.add_task(
        process_document_pipeline_wrapper, 
        doc_id=doc_id, 
        file_path=file_location, 
        department=current_user.department # Pass department to background task
    )
    logger.info(f"Background task added for doc_id: {doc_id}")

    # Return the created DB record
    return db_doc

@router.get("/", response_model=schemas.DocumentListResponse)
async def list_documents(
    db: Session = Depends(get_db),
    current_user: models.User = Depends(deps.get_current_user),
    skip: int = Query(0, ge=0),
    limit: int = Query(10, ge=1, le=100)
) -> Any:
    """
    List documents for the authenticated user's department with pagination.
    """
    logger.info(f"Listing documents for department: {current_user.department}, skip={skip}, limit={limit}")
    try:
        documents = crud.crud_document.get_documents_by_department(
            db=db, department=current_user.department, skip=skip, limit=limit
        )
        total_count = crud.crud_document.count_documents_by_department(
            db=db, department=current_user.department
        )
        return {"documents": documents, "total_count": total_count}
    except Exception as e:
        logger.error(f"Error listing documents for department {current_user.department}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to retrieve documents")

@router.get("/{document_id}", response_model=schemas.Document)
async def get_document(
    document_id: str,
    db: Session = Depends(get_db),
    current_user: models.User = Depends(deps.get_current_user),
) -> Any:
    """
    Get a specific document by ID, ensuring it belongs to the user's department.
    """
    logger.info(f"Getting document details for ID: {document_id}, department: {current_user.department}")
    db_doc = crud.crud_document.get_document(
        db=db, doc_id=document_id, department=current_user.department
    )
    if not db_doc:
        logger.warning(f"Document not found or not authorized: {document_id}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found or user not authorized",
        )
    return db_doc

@router.delete("/{document_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_document(
    document_id: str,
    background_tasks: BackgroundTasks, # Added for background deletion
    db: Session = Depends(get_db),
    current_user: models.User = Depends(deps.get_current_user),
) -> None:
    """
    Delete a document by ID, ensuring it belongs to the user's department.
    Includes deleting the file, DB record, and triggering vector embedding deletion.
    """
    logger.info(f"Attempting to delete document: {document_id} for department: {current_user.department}")
    # Verify document exists and belongs to the user's department before proceeding
    db_doc = crud.crud_document.get_document(
        db=db, doc_id=document_id, department=current_user.department
    )
    if not db_doc:
        logger.warning(f"Document not found or not authorized for deletion: {document_id}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found or user not authorized for deletion",
        )

    # 1. Trigger Vector Store Deletion (in background)
    background_tasks.add_task(document_processor.delete_document_vectors, doc_id=document_id)
    logger.info(f"Background task added to delete vectors for doc_id: {document_id}")

    # 2. Delete File from Storage
    file_path = db_doc.storage_path
    if file_path and os.path.exists(file_path):
        try:
            os.remove(file_path)
            logger.info(f"Deleted file: {file_path}")
        except Exception as e:
            logger.error(f"Failed to delete file {file_path} for doc_id {document_id}: {e}", exc_info=True)
            # Log error but continue deletion
    elif file_path:
        logger.warning(f"File path recorded but not found for doc_id {document_id}: {file_path}")

    # 3. Delete from Database using CRUD
    deleted_doc = crud.crud_document.delete_document(
        db=db, doc_id=document_id, department=current_user.department
    )
    if not deleted_doc:
        # This case should ideally not happen if we found it earlier
        logger.error(f"Document {document_id} disappeared during delete operation.")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Document not found during delete.")

    logger.info(f"Successfully deleted document {document_id} record from DB.")
    # Return 204 No Content implicitly
    return None

