from fastapi import (
    APIRouter, 
    Depends, 
    HTTPException, 
    status, 
    UploadFile, 
    File, 
    BackgroundTasks,
    Query,
    Form  # Add Form for department parameter
)
from typing import Any, List, Dict
import os
import uuid
from datetime import datetime
import time
import logging
import asyncio

# Assuming schemas are defined correctly elsewhere
from app.schemas.documents import DocumentCreate, Document, DocumentList

# --- Example Pydantic models (replace with your actual schemas) ---
from pydantic import BaseModel, Field

# Import the actual document processing function
from app.services.document_processor import process_and_store_document

class DocumentMetadata(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    filename: str
    content_type: str | None = None
    size: int
    upload_date: datetime = Field(default_factory=datetime.now)
    status: str = "pending"
    path: str | None = None
    department: str = "General"  # Add department field
    error_message: str | None = None

class DocumentList(BaseModel):
    documents: List[DocumentMetadata]
    total_count: int

# Setup logger
logger = logging.getLogger(__name__)

router = APIRouter()

# --- Configuration ---
UPLOAD_DIR = "/app/data/uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# Valid departments (matching the frontend dropdown)
VALID_DEPARTMENTS = ["General", "IT", "HR", "Finance", "Legal"]

# --- Global In-Memory Store (Placeholder) ---
documents_db: Dict[str, Dict[str, Any]] = {}

# ================================================
# Enhanced Document Processing with Department Support
# ================================================
async def process_document_pipeline(doc_id: str, file_path: str, filename: str, department: str = "General"):
    """
    Background task to process the uploaded document with department categorization.
    """
    print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline ENTRY] doc_id: {doc_id}, file: {filename}, department: {department} ---")
    logger.info(f"--- LOGGER: [BACKGROUND TASK process_document_pipeline ENTRY] doc_id: {doc_id}, file: {filename}, department: {department} ---")
    
    global documents_db
    processing_start_time = time.time()
    
    try:
        logger.info(f"[{doc_id}] Inside try block of process_document_pipeline.")
        
        # Update Status to Processing
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "processing"
            documents_db[doc_id]["department"] = department
            logger.info(f"[{doc_id}] Status set to 'processing' and department set to '{department}' in placeholder DB.")
        else:
            logger.warning(f"[{doc_id}] doc_id not found in placeholder DB to set status to 'processing'.")

        # Call the document processing function with robust error handling
        logger.info(f"[{doc_id}] Attempting to call document_processor.process_and_store_document for file: {file_path}")
        
        try:
            # Try with department parameter first (newer version)
            await process_and_store_document(file_path=file_path, department=department.lower())
            logger.info(f"[{doc_id}] Successfully called process_and_store_document with department parameter: {department}")
        except TypeError as e:
            if "unexpected keyword argument 'department'" in str(e):
                logger.info(f"[{doc_id}] Department parameter not supported, trying without it")
                # Try without department parameter (older version)
                await process_and_store_document(file_path=file_path)
                logger.info(f"[{doc_id}] Successfully called process_and_store_document without department parameter")
            else:
                # Re-raise if it's a different TypeError
                raise e
        
        logger.info(f"[{doc_id}] Call to document_processor.process_and_store_document completed.")

        # Update Status to Completed
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "completed"
            processing_time = time.time() - processing_start_time
            logger.info(f"[{doc_id}] Status set to 'completed' in placeholder DB. Processing time: {processing_time:.2f}s")
        else:
            logger.warning(f"[{doc_id}] doc_id not found in placeholder DB to set status to 'completed'.")

    except Exception as e:
        error_msg = f"[BACKGROUND TASK] Unhandled error in processing pipeline for doc_id {doc_id}: {e}"
        print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline ERROR] doc_id: {doc_id}, error: {e} ---")
        logger.error(error_msg, exc_info=True)
        
        # Update Status to Failed
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "failed"
            documents_db[doc_id]["error_message"] = str(e)
            logger.info(f"[{doc_id}] Status set to 'failed' in placeholder DB due to unhandled error.")
        else:
            logger.warning(f"[{doc_id}] doc_id not found in placeholder DB to set status to 'failed'.")
    
    finally:
        print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline EXIT] doc_id: {doc_id} ---")
        logger.info(f"--- LOGGER: [BACKGROUND TASK process_document_pipeline EXIT] doc_id: {doc_id} ---")

# ================================================
# API Endpoints
# ================================================

@router.post("/", response_model=dict)
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    department: str = Form(default="General")  # Add department parameter
):
    """
    Upload a document with department categorization.
    """
    # Validate department
    if department not in VALID_DEPARTMENTS:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid department. Must be one of: {', '.join(VALID_DEPARTMENTS)}"
        )
    
    logger.info(f"--- API POST /documents - Received file: {file.filename}, Department: {department} ---")
    
    # Generate unique document ID
    doc_id = str(uuid.uuid4())
    
    try:
        # Create upload directory if it doesn't exist
        os.makedirs(UPLOAD_DIR, exist_ok=True)
        
        # Generate unique filename to avoid conflicts
        file_extension = os.path.splitext(file.filename)[1]
        unique_filename = f"{doc_id}_{file.filename}"
        file_path = os.path.join(UPLOAD_DIR, unique_filename)
        
        # Save file to disk
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        file_size = len(content)
        logger.info(f"[{doc_id}] File saved: {file_path}, size: {file_size}")
        
        # Create document metadata for placeholder DB
        doc_metadata = {
            "id": doc_id,
            "filename": file.filename,
            "content_type": file.content_type,
            "size": file_size,
            "upload_date": datetime.now(),
            "status": "pending",
            "department": department,
            "path": file_path,
            "error_message": None
        }
        
        # Store in placeholder DB
        documents_db[doc_id] = doc_metadata
        logger.info(f"[{doc_id}] Initial metadata saved to placeholder DB with department: {department}.")
        
        # Add background task for processing
        logger.info(f"[{doc_id}] Adding background task for file: {file_path}")
        background_tasks.add_task(
            process_document_pipeline,
            doc_id=doc_id,
            file_path=file_path,
            filename=file.filename,
            department=department  # Pass department to background task
        )
        logger.info(f"[{doc_id}] Successfully added background task.")
        
        return {
            "message": f"File '{file.filename}' uploaded successfully to {department} department",
            "document_id": doc_id,
            "department": department,
            "status": "pending"
        }
        
    except Exception as e:
        logger.error(f"[{doc_id}] Error during upload: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

@router.get("/", response_model=DocumentList)
async def list_documents(
    skip: int = Query(0, ge=0, description="Number of documents to skip"),
    limit: int = Query(10, ge=1, le=100, description="Number of documents to return"),
    department: str = Query(None, description="Filter by department")
):
    """
    List uploaded documents with optional department filtering.
    """
    try:
        # Get real uploaded documents from filesystem
        upload_dir = "/app/data/uploads"
        documents = []
        
        if os.path.exists(upload_dir):
            for filename in os.listdir(upload_dir):
                if filename.endswith((".pdf", ".txt", ".docx")):
                    file_path = os.path.join(upload_dir, filename)
                    file_stat = os.stat(file_path)
                    
                    # Extract document ID from filename (format: id_originalname.ext)
                    if "_" in filename:
                        doc_id = filename.split("_")[0]
                        original_name = "_".join(filename.split("_")[1:])
                    else:
                        doc_id = filename
                        original_name = filename
                    
                    # Get department from placeholder DB or default to General
                    doc_department = "General"
                    doc_status = "uploaded"
                    if doc_id in documents_db:
                        doc_department = documents_db[doc_id].get("department", "General")
                        doc_status = documents_db[doc_id].get("status", "uploaded")
                    
                    # Apply department filter if specified
                    if department and doc_department.lower() != department.lower():
                        continue
                    
                    # Create DocumentMetadata object
                    doc_metadata = DocumentMetadata(
                        id=doc_id,
                        filename=original_name,
                        content_type="application/pdf" if filename.endswith(".pdf") else "text/plain",
                        size=file_stat.st_size,
                        status=doc_status,
                        department=doc_department,
                        path=file_path
                    )
                    documents.append(doc_metadata)
        
        # Apply pagination
        paginated_docs = documents[skip:skip + limit]
        total_count = len(documents)
        
        filter_info = f", filtered by department: {department}" if department else ""
        logger.info(f"API GET /documents - Listing documents from filesystem, skip={skip}, limit={limit}{filter_info}, returning {len(paginated_docs)} of {total_count}")
        
        return DocumentList(documents=paginated_docs, total_count=total_count)
        
    except Exception as e:
        logger.error(f"API GET /documents - Error listing documents: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to retrieve documents")

@router.delete("/{document_id}")
async def delete_document(document_id: str):
    """
    Delete a document by ID.
    """
    try:
        # Find the document file
        upload_dir = "/app/data/uploads"
        deleted = False
        
        if os.path.exists(upload_dir):
            for filename in os.listdir(upload_dir):
                if filename.startswith(f"{document_id}_"):
                    file_path = os.path.join(upload_dir, filename)
                    os.remove(file_path)
                    deleted = True
                    logger.info(f"Deleted file: {file_path}")
                    break
        
        # Remove from placeholder DB
        if document_id in documents_db:
            del documents_db[document_id]
            logger.info(f"Removed document {document_id} from placeholder DB")
        
        if deleted:
            return {"message": f"Document {document_id} deleted successfully"}
        else:
            raise HTTPException(status_code=404, detail="Document not found")
            
    except Exception as e:
        logger.error(f"Error deleting document {document_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to delete document")

@router.get("/departments")
async def get_departments():
    """
    Get list of valid departments.
    """
    return {
        "departments": VALID_DEPARTMENTS,
        "default": "General"
    }
