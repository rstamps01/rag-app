"""
Corrected Documents Route - Fixes Function Signature Mismatch
This version properly calls process_and_store_document with the correct parameters
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, BackgroundTasks, status, Form
from typing import List, Optional
import os
import uuid
import time
import logging
from pathlib import Path

# Import the document processor function
from app.services.document_processor import process_and_store_document
from app.schemas.document import DocumentMetadata

logger = logging.getLogger(__name__)

router = APIRouter()

# Global placeholder database for document metadata
documents_db = {}

async def process_document_pipeline(doc_id: str, file_path: str, filename: str, department: str):
    """
    CORRECTED: Background task to process document with proper function call
    """
    print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline ENTRY] doc_id: {doc_id}, file: {filename}, department: {department} ---")
    logger.info(f"--- LOGGER: [BACKGROUND TASK process_document_pipeline ENTRY] doc_id: {doc_id}, file: {filename}, department: {department} ---")
    
    global documents_db
    processing_start_time = time.time()
    
    try:
        logger.info(f"[{doc_id}] Inside try block of process_document_pipeline.")
        
        # 1. Update Status to Processing
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "processing"
            documents_db[doc_id]["department"] = department
            logger.info(f"[{doc_id}] Status set to 'processing' and department set to '{department}' in placeholder DB.")
        else:
            logger.warning(f"[{doc_id}] doc_id not found in placeholder DB to set status to 'processing'.")

        # 2. CORRECTED: Call the function with the correct signature
        logger.info(f"[{doc_id}] Attempting to call document_processor.process_and_store_document for file: {file_path}")
        
        # The function signature is: async def process_and_store_document(file_path: str, department: str)
        await process_and_store_document(file_path, department)
        
        logger.info(f"[{doc_id}] Successfully called process_and_store_document")

        # 3. Update Status to Completed
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "completed"
            processing_time = time.time() - processing_start_time
            logger.info(f"[{doc_id}] Status set to 'completed' in placeholder DB. Processing time: {processing_time:.2f}s")
        else:
            logger.warning(f"[{doc_id}] doc_id not found in placeholder DB to set status to 'completed'.")

    except Exception as e:
        error_msg = f"[BACKGROUND TASK] Unhandled error in processing pipeline for doc_id {doc_id}: {e}"
        logger.error(error_msg, exc_info=True)
        print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline ERROR] doc_id: {doc_id}, error: {e} ---")
        
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "failed"
            documents_db[doc_id]["error_message"] = str(e)
            logger.info(f"[{doc_id}] Status set to 'failed' in placeholder DB due to unhandled error.")
        else:
            logger.warning(f"[{doc_id}] doc_id not found in placeholder DB to set status to 'failed' after unhandled error.")
    
    finally:
        logger.info(f"--- LOGGER: [BACKGROUND TASK process_document_pipeline EXIT] doc_id: {doc_id} ---")
        print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline EXIT] doc_id: {doc_id} ---")

@router.post("/", response_model=DocumentMetadata, status_code=status.HTTP_202_ACCEPTED)
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    department: str = Form(default="General")  # ADDED: Department form field
):
    """
    CORRECTED: Upload document with department selection support
    """
    logger.info(f"--- API POST /documents - Received file: {file.filename}, Department: {department} ---")
    
    # Validate department
    valid_departments = ["General", "IT", "HR", "Finance", "Legal"]
    if department not in valid_departments:
        logger.warning(f"Invalid department '{department}', defaulting to 'General'")
        department = "General"
    
    # Generate unique document ID
    doc_id = str(uuid.uuid4())
    
    # Create upload directory if it doesn't exist
    upload_dir = Path("/app/data/uploads")
    upload_dir.mkdir(parents=True, exist_ok=True)
    
    # Save file with unique name
    file_extension = Path(file.filename).suffix
    unique_filename = f"{doc_id}_{file.filename}"
    file_path = upload_dir / unique_filename
    
    try:
        # Save uploaded file
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        file_size = len(content)
        logger.info(f"[{doc_id}] File saved: {file_path}, size: {file_size}")
        
        # Store initial metadata in placeholder DB
        documents_db[doc_id] = {
            "id": doc_id,
            "filename": file.filename,
            "file_path": str(file_path),
            "department": department,
            "status": "pending",
            "upload_time": time.time(),
            "file_size": file_size,
            "content_type": file.content_type
        }
        
        logger.info(f"[{doc_id}] Initial metadata saved to placeholder DB with department: {department}.")
        
        # Add background task for processing
        logger.info(f"[{doc_id}] Adding background task for file: {file_path}")
        background_tasks.add_task(
            process_document_pipeline,
            doc_id=doc_id,
            file_path=str(file_path),
            filename=file.filename,
            department=department  # CORRECTED: Pass the actual department from form
        )
        logger.info(f"[{doc_id}] Successfully added background task.")
        
        # Return document metadata
        return DocumentMetadata(
            id=doc_id,
            filename=file.filename,
            department=department,
            status="pending",
            upload_time=documents_db[doc_id]["upload_time"],
            file_size=file_size,
            content_type=file.content_type
        )
        
    except Exception as e:
        logger.error(f"[{doc_id}] Error uploading document: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error uploading document: {str(e)}"
        )

@router.get("/", response_model=List[DocumentMetadata])
async def list_documents(skip: int = 0, limit: int = 100):
    """
    ENHANCED: List documents with department information
    """
    try:
        # Get documents from filesystem (existing logic)
        upload_dir = Path("/app/data/uploads")
        if not upload_dir.exists():
            logger.info("Upload directory does not exist, returning empty list")
            return []
        
        documents = []
        files = list(upload_dir.glob("*"))
        files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        for file_path in files[skip:skip + limit]:
            if file_path.is_file():
                # Extract doc_id from filename (format: doc_id_original_filename)
                filename_parts = file_path.name.split('_', 1)
                if len(filename_parts) >= 2:
                    doc_id = filename_parts[0]
                    original_filename = filename_parts[1]
                else:
                    doc_id = str(uuid.uuid4())
                    original_filename = file_path.name
                
                # Get metadata from placeholder DB or create default
                if doc_id in documents_db:
                    doc_metadata = documents_db[doc_id]
                    status_val = doc_metadata.get("status", "unknown")
                    department = doc_metadata.get("department", "General")
                    upload_time = doc_metadata.get("upload_time", file_path.stat().st_mtime)
                    content_type = doc_metadata.get("content_type", "application/octet-stream")
                else:
                    status_val = "unknown"
                    department = "General"  # Default department
                    upload_time = file_path.stat().st_mtime
                    content_type = "application/octet-stream"
                
                documents.append(DocumentMetadata(
                    id=doc_id,
                    filename=original_filename,
                    department=department,  # ADDED: Department information
                    status=status_val,
                    upload_time=upload_time,
                    file_size=file_path.stat().st_size,
                    content_type=content_type
                ))
        
        logger.info(f"API GET /documents - Listing documents from filesystem, skip={skip}, limit={limit}, returning {len(documents)} of {len(files)}")
        return documents
        
    except Exception as e:
        logger.error(f"Error listing documents: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error listing documents: {str(e)}"
        )

@router.get("/departments")
async def get_departments():
    """
    NEW: Get list of available departments
    """
    return {
        "departments": ["General", "IT", "HR", "Finance", "Legal"]
    }
