# File Path: /backend/app/api/routes/documents.py
# GITHUB-COMPATIBLE VERSION - Uses existing schema classes and field names

import os
import uuid
import time
import logging
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, status, File, UploadFile, Form, BackgroundTasks
from sqlalchemy.orm import Session

# FIXED: Import from existing schema structure
from app.schemas.documents import DocumentCreate, DocumentUpdate, Document
from app.crud.crud_document import create_document, get_documents, get_document, update_document
from app.db.session import get_db
from app.services.document_processor import process_and_store_document
from app.core.config import settings

logger = logging.getLogger(__name__)

router = APIRouter()

# ENHANCED: Department validation
VALID_DEPARTMENTS = ["General", "IT", "HR", "Finance", "Legal"]

# In-memory storage for immediate status tracking (placeholder DB)
documents_db = {}

async def process_document_pipeline(doc_id: str, file_path: str, filename: str, content_type: str, department: str, db_document_id: str):
    """
    FIXED: Background task for document processing with corrected status logic
    
    Args:
        doc_id: Unique document processing ID
        file_path: Path to uploaded file
        filename: Original filename
        content_type: MIME type
        department: Department for categorization
        db_document_id: Database document ID from initial creation
    """
    processing_start_time = time.time()
    
    logger.info(f"--- LOGGER: [BACKGROUND TASK process_document_pipeline ENTRY] doc_id: {doc_id}")
    print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline ENTRY] doc_id: {doc_id}")
    
    try:
        logger.info(f"[{doc_id}] Inside try block of process_document_pipeline")
        
        # 1. Update status to processing in placeholder DB
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "processing"
            documents_db[doc_id]["department"] = department
            logger.info(f"[{doc_id}] Status set to 'processing' and department set to '{department}' in placeholder DB")
        
        # 3. FIXED: Call document processor with correct signature and handle result
        logger.info(f"[{doc_id}] Attempting to call document_processor.process_and_store_document")
        
        # FIXED: Call with GitHub-compatible signature (4 parameters)
        result = process_and_store_document(
            file_path=file_path,
            filename=filename,
            content_type=content_type,
            db=db
        )
        
        logger.info(f"[{doc_id}] Successfully called process_and_store_document")
        logger.info(f"[{doc_id}] Processing result: {result}")
        
        # 4. FIXED: Update status based on actual processing result
        if isinstance(result, dict):
            processing_result = result.get("processing_result", {})
            actual_status = processing_result.get("status", "completed" if result.get("success", True) else "failed")
            error_message = processing_result.get("error") or result.get("error")
        else:
            # If result is not a dict, assume success
            actual_status = "completed"
            error_message = None
        
        # Update placeholder DB with actual result
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = actual_status
            if error_message:
                documents_db[doc_id]["error_message"] = error_message
            processing_time = time.time() - processing_start_time
            logger.info(f"[{doc_id}] Status set to '{actual_status}' in placeholder DB")
        else:
            logger.warning(f"[{doc_id}] doc_id not found in placeholder DB")
        
        # Update database with actual result
        if db_document_id:
            # Get a fresh database session for background task
            db = next(get_db())
            try:
                # FIXED: Use correct function name from CRUD
                db_document = get_document(db, doc_id=db_document_id)
                if db_document:
                    document_update = DocumentUpdate(
                        status=actual_status,
                        error_message=error_message
                    )
                    update_document(db, db_document, document_update)
                    logger.info(f"[{doc_id}] Status set to '{actual_status}' in database.")
                else:
                    logger.warning(f"[{doc_id}] doc_id not found in placeholder DB")
            finally:
                db.close()
        
    except Exception as e:
        error_msg = f"[BACKGROUND TASK] Unhandled error in processing pipeline: {str(e)}"
        logger.error(error_msg, exc_info=True)
        print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline ERROR] doc_id: {doc_id}, error: {str(e)}")
        
        # FIXED: Set status to failed on error
        if doc_id in documents_db:
            documents_db[doc_id]["status"] = "failed"
            documents_db[doc_id]["error_message"] = str(e)
            logger.info(f"[{doc_id}] Status set to 'failed' in placeholder DB")
        
        # Update database with actual result
        if db_document_id:
            db = next(get_db())
            try:
                # FIXED: Use correct function name from CRUD
                db_document = get_document(db, doc_id=db_document_id)
                if db_document:
                    document_update = DocumentUpdate(
                        status="failed",
                        error_message=str(e)
                    )
                    update_document(db, db_document, document_update)
                    logger.info(f"[{doc_id}] Status set to 'failed' in database.")
            finally:
                db.close()
    
    finally:
        logger.info(f"--- LOGGER: [BACKGROUND TASK process_document_pipeline EXIT] doc_id: {doc_id}")
        print(f"--- PRINT: [BACKGROUND TASK process_document_pipeline EXIT] doc_id: {doc_id}")

@router.post("/", response_model=Document, status_code=status.HTTP_202_ACCEPTED)
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    department: str = Form("General"),
    db: Session = Depends(get_db)
):
    """
    FIXED: Upload document with corrected status logic and single document creation
    
    Args:
        background_tasks: FastAPI background tasks
        file: Uploaded file
        department: Department for categorization (default: General)
        db: Database session
        
    Returns:
        Document with upload confirmation
    """
    
    # ENHANCED: Validate department
    if department not in VALID_DEPARTMENTS:
        logger.warning(f"Invalid department '{department}', defaulting to 'General'")
        department = "General"
    
    # Generate unique document ID for tracking
    doc_id = str(uuid.uuid4())
    
    logger.info(f"--- API POST /documents - Received file: {file.filename}, Department: {department}")
    
    try:
        # 1. Save uploaded file
        upload_dir = "/app/data/uploads"
        os.makedirs(upload_dir, exist_ok=True)
        
        file_extension = os.path.splitext(file.filename)[1]
        unique_filename = f"{doc_id}_{file.filename}"
        file_path = os.path.join(upload_dir, unique_filename)
        
        # Save file to disk
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        file_size = len(content)
        logger.info(f"[{doc_id}] File saved: {file_path}, size: {file_size}")
        
        # 2. FIXED: Create single document record in database
        document_create = DocumentCreate(
            filename=file.filename,
            content_type=file.content_type
        )
        
        db_document = create_document(db, document_create)
        logger.info(f"[{doc_id}] Document created in database with ID: {db_document.id}")
        
        # 3. Store in placeholder DB for immediate status tracking
        documents_db[doc_id] = {
            "id": str(db_document.id),
            "filename": file.filename,
            "content_type": file.content_type,
            "department": department,
            "size": file_size,
            "status": "uploaded",
            "upload_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "path": file_path
        }
        
        logger.info(f"[{doc_id}] Initial metadata saved to placeholder DB with status 'uploaded'")
        
        # 4. Add background processing task
        logger.info(f"[{doc_id}] Adding background task for file: {file_path}")
        
        background_tasks.add_task(
            process_document_pipeline,
            doc_id=doc_id,
            file_path=file_path,
            filename=file.filename,
            content_type=file.content_type,
            department=department,
            db_document_id=str(db_document.id)
        )
        
        # Return document with processing status
        return Document(
            id=db_document.id,
            filename=db_document.filename,
            content_type=db_document.content_type,
            size=file_size,
            upload_date=db_document.upload_date,
            department=department,
            status="processing"
        )
        
    except Exception as e:
        logger.error(f"Error uploading document: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error uploading document: {str(e)}")

@router.get("/", response_model=List[Document])
def list_documents(
    skip: int = 0,
    limit: int = 100,
    department: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    List documents with optional filtering.
    
    Args:
        skip: Number of records to skip
        limit: Maximum number of records to return
        department: Optional department filter
        db: Database session
        
    Returns:
        List of documents
    """
    try:
        documents = get_documents(db=db, skip=skip, limit=limit, department=department)
        
        # Convert to response format with field mapping
        result = []
        for doc in documents:
            result.append(Document(
                id=doc.id,
                filename=doc.filename,
                content_type=doc.content_type,
                size=getattr(doc, 'size', 0),
                upload_date=doc.upload_date,
                department=getattr(doc, 'department', 'General'),
                status=getattr(doc, 'status', 'unknown'),
                error_message=getattr(doc, 'error_message', None)
            ))
        
        return result
        
    except Exception as e:
        logger.error(f"Error listing documents: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error listing documents: {str(e)}")

@router.get("/{document_id}", response_model=Document)
def get_document_by_id(document_id: str, db: Session = Depends(get_db)):
    """
    Get a specific document by ID.
    
    Args:
        document_id: Document ID
        db: Database session
        
    Returns:
        Document object
    """
    try:
        # FIXED: Use correct function name from CRUD
        db_document = get_document(db, doc_id=document_id)
        if not db_document:
            raise HTTPException(status_code=404, detail="Document not found")
        
        return Document(
            id=db_document.id,
            filename=db_document.filename,
            content_type=db_document.content_type,
            size=getattr(db_document, 'size', 0),
            upload_date=db_document.upload_date,
            department=getattr(db_document, 'department', 'General'),
            status=getattr(db_document, 'status', 'unknown'),
            error_message=getattr(db_document, 'error_message', None)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting document {document_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error getting document: {str(e)}")

@router.delete("/{document_id}")
def delete_document_by_id(document_id: str, db: Session = Depends(get_db)):
    """
    Delete a document by ID.
    
    Args:
        document_id: Document ID
        db: Database session
        
    Returns:
        Success message
    """
    try:
        # FIXED: Use correct function name from CRUD
        db_document = get_document(db, doc_id=document_id)
        if not db_document:
            raise HTTPException(status_code=404, detail="Document not found")
        
        # Delete from database (assuming delete function exists)
        # delete_document(db=db, doc_id=document_id)
        
        return {"message": f"Document {document_id} deleted successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting document {document_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error deleting document: {str(e)}")
