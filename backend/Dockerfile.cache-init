# Fixed Cache Initialization Dockerfile for RAG Application
FROM nvidia/cuda:12.8.0-runtime-ubuntu22.04

WORKDIR /app

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV CUDA_VISIBLE_DEVICES=0

# Install system dependencies and create Python symlink
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 \
    python3-pip \
    python3-dev \
    build-essential \
    tesseract-ocr \
    tesseract-ocr-eng \
    libpq-dev \
    && ln -s /usr/bin/python3 /usr/bin/python \
    && rm -rf /var/lib/apt/lists/*

# Install NVIDIA CUDA libraries
RUN pip3 install --no-cache-dir \
    nvidia-cublas-cu12==12.8.4.1 \
    nvidia-cuda-cupti-cu12==12.8.90 \
    nvidia-cuda-nvrtc-cu12==12.8.93 \
    nvidia-cuda-runtime-cu12==12.8.90 \
    nvidia-cudnn-cu12==9.10.2.21 \
    nvidia-cufft-cu12==11.3.3.83 \
    nvidia-cufile-cu12==1.13.1.3 \
    nvidia-curand-cu12==10.3.9.90 \
    nvidia-cusolver-cu12==11.7.3.90 \
    nvidia-cusparse-cu12==12.5.8.93 \
    nvidia-cusparselt-cu12==0.7.1 \
    nvidia-nccl-cu12==2.27.3 \
    nvidia-nvjitlink-cu12==12.8.93 \
    nvidia-nvshmem-cu12==3.3.9 \
    nvidia-nvtx-cu12==12.8.90 \
    --index-url https://download.pytorch.org/whl/nightly/cu128

# Install PyTorch with CUDA 12.8 support
RUN pip3 install --no-cache-dir \
    torch==2.9.0.dev20250708+cu128 \
    torchvision==0.24.0.dev20250708+cu128 \
    pytorch-triton==3.4.0+gitae848267 \
    --index-url https://download.pytorch.org/whl/nightly/cu128

# Copy and install requirements
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# Create cache directories
RUN mkdir -p /app/models_cache /app/scripts

# Copy cache utilities and initialization scripts
COPY scripts/model_cache_utils.py /app/scripts/
COPY scripts/initialize_model_cache.py /app/scripts/

# Make scripts executable
RUN chmod +x /app/scripts/*.py

# Set up cache environment variables
ENV HF_HOME=/app/models_cache
#ENV TRANSFORMERS_CACHE=/app/models_cache
ENV HF_DATASETS_CACHE=/app/models_cache
ENV HF_HUB_CACHE=/app/models_cache
ENV MODELS_CACHE_DIR=/app/models_cache

# Expose port
EXPOSE 8000

# Use python3 explicitly in CMD to ensure compatibility
CMD ["python3", "/app/scripts/initialize_model_cache.py"]